<!DOCTYPE HTML>
<html>

<head>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-122922834-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-122922834-1');
</script>

  <title>Lifu Huang</title>
  <meta name="description" content="website description" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="style/style.css" title="style" />
</head>

<body>
  <div id="main">

    <div id="header">
          <div id="menubar">
            <ul id="menu">
              <li><a href="index.html">Home</a></li>
              <li><a href="publications.html">Publications</a></li>
              <!-- <li><a href="research.html">Research</a></li> -->
              <li><a href="lab.html">NLP Lab</a></li>
              <li><a href="teaching.html">Teaching</a></li>
              <!-- <li><a href="experience.html">Experience</a></li> -->
              <li><a href="service.html">Service</a></li>
            </ul>
          </div>
    </div>

        <div id="site_content">
      <div class="sidebar">
        <div align="center"> 
          <div class="trig1" align="center"> 
            <img class="trig" src="style/lifu.jpeg">
          </div>
        </div>

        <div align="center">
          <br />
          <strong> <font face="verdana" size=4 color="#7b241c">Lifu Huang</font> </strong>
          <br />
          <br />
        </div>
        <div align="center">
          <p>
          <font face="verdana" size=2 color="#000000"> <a class="a:link" href="lab.html" target=_blank>Natural Language Processing Lab</a>, </font>
      	  </p>
      	  <p>
          <!-- <br /> -->
          <font face="verdana" size=2 color="#000000"> Computer Science Department, </font>
      	  </p>
          <!-- <br /> -->
          <p>
          <font face="verdana" size=2 color="#000000">Virginia Tech</font>
      	  </p>
          <!-- <br /> -->
          <p>
          <font face="verdana" size=2 color="#000000">Email: lifuh@vt.edu</font>
          </p> 
          <p></p>         
        </div>
          <img class="cv" border="0" width=16px height=14px src="style/location.png" /> <font face="verdana" size=2> Blacksburg, Virginia, USA</font>
           <p></p><!-- <br/> -->
          <!-- <a class="a:link" href="./files/LifuHuang-CV-20190528.pdf" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/cv.png" /> <font face="verdana" size=2 >Curriculum Vitae</font></a> <p></p> --><!-- <br /> -->
          <a class="a:link" href="https://scholar.google.com.sg/citations?user=76IEGtYAAAAJ&hl=en" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/scholar.png" /> <font face="verdana" size=2 >Google Scholar</font> </a>  <p></p><!-- <br /> -->
          <a class="a:link" href="https://github.com/wilburOne" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/github.svg" /> <font face="verdana" size=2 >Github</font> </a>  <p></p><!-- <br /> -->
          <a class="a:link" href="https://twitter.com/lifu_huang" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/twitter.png" /> <font face="verdana" size=2 >Twitter</font> </a>  <p></p><!-- <br /> -->
          <!-- <a class="a:link" href="https://www.facebook.com/warrior.fu" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/facebook.png" /> <font size=2>Facebook</font> </a> <br /> -->
          <!-- <a class="a:link" href="https://www.linkedin.com/in/huang-lifu-3727ab57/" target=_blank> <img class="cv" border="0" width=16px height=16px src="style/linkedin.png" /> <font size=2>LinkedIn</font> </a>  -->
          <br />
          <br />
      </div>


      <div id="content">
        <h4>
        <p>
        	I am an Assistant Professor of the <a class="a:link" href="https://cs.vt.edu/" target=_blank>Computer Science Department</a> at <a class="a:link" href="https://vt.edu/" target=_blank>Virginia Tech</a>, where I lead the <a class="a:link" href="#" target=_blank>Natural Language Processing Lab</a>. At VT CS, I'm also a member of the <a class="a:link" href="https://sanghani.cs.vt.edu/"  target=_blank>Sanghani Center for Artificial Intelligence and Discovery Analytics</a>. 
        </p>
        <p>
        	Prior to VT, I received my Ph.D. in Computer Science from UIUC where I worked with <a class="a:link" href="http://nlp.cs.rpi.edu/hengji.html"  target=_blank>Heng Ji</a>. I have also worked at Singapore Management University, Microsoft Rsearch Asia, IBM Watson Research, and Allen Institute AI (AI2). I am a recipient of the 2019 AI2 Fellowship, 2021 Amazon Research Award, 2023 VT-Amazon Initiative Research Award, 2023 Department Rising Star Award and 2023 NSF CAREER award. My research has been recognized with the awards including ACL'2023 Outstanding Paper Award and SIGIR'2023 Best Paper Award Honorable Mention.
        </p>

        <p>
        	My research focuses on Natural Language Processing, Machine Learning and Artificial Intelligence. I'm interested in building efficient models and benchmarks that can encourage machines to perform human-level intelligence. My current research interests include information extraction, language understanding and generation, conversational AI and multimodal.

<!--         	<div id="interests">
	        	<ul>
		        	<li> <strong>Knowledge extraction with limited supervision</strong>: information extraction with (weak) supervision, automatic schema induction, knowledge-enpowered information extraction, few/zero shot learning.</li>
		        	<li> <strong>Multimodal learning</strong> with pre-trained vision-language models, Embodied AI.</li>
		        	<li> <strong>Natural language understanding, reasoning, generation</strong> and more beyond.</li> -->
		        	<!-- <li> <strong>Natural language generation</strong> </li> -->
		        	<!-- <li> <strong>Representation learning</strong>: domain adaptation, cross-lingual transfer </li> -->
<!-- 	        	</ul>
        	</div> -->
    	</p>

<!--     	<p>
        	We are grateful to DARPA, U.S. Air Force, Amazon (AWS and Alexa AI), and Meta for supporting our research!
        </p> -->

        <p><font color="#C0392B"> <strong>I'm always looking for highly motivated students to work with me on broad NLP and Multimodal research. Please feel free to reach out and apply!</strong></font> </p>
        </h4>

        <h1><u><strong>News and Highlights</strong></u></h1>
        <div id="news">
        <ul>
		<li><h4> <strong> (02/15/24) </strong>: Glad to receive an NSF award support our research on <a class="a:link" href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2330940"  target=_blank>conversational AI for combating cybergrooming</a>.</h4></li>
        <li><h4> <strong> (02/12/24) </strong>: Grateful to receive a new grant from the DARPA <a class="a:link" href="https://sam.gov/opp/dd906dc45ee347d5a0c29d980cf67dcc/view"  target=_blank>FoundSci</a> program to support our research on developing foundation models for novel material design.</h4></li>
        <li><h4> <strong> (01/18/24) </strong>: One paper about <a class="a:link" href="https://arxiv.org/pdf/2305.14725.pdf"  target=_blank>attribute-aware multimodal entity linking</a> is accepted by EACL'2024. Congrats to Barry and all collaborators.</h4></li>
        <li><h4> <strong> (12/09/23) </strong>: <img width=18px height=18px src="style/champion.png" />Honored to receive the <strong>Outstanding Area Chair award</strong> from EMNLP'2023.</h4></li>
        <li><h4> <strong> (12/08/23) </strong>: One paper about <a class="a:link" href="https://arxiv.org/pdf/2310.04965.pdf"  target=_blank>multimodal script learning</a> is accepted by AAAI'2024. Congrats to Jingyuan, Minqian, and Zhiyang.</h4></li>
        <li><h4> <strong> (10/08/23) </strong>: Three papers accepted by EMNLP'2023. Congrats to Jingyuan, Zhiyang, Ying and Minqian.</h4></li>
        <li><h4> <strong> (10/06/23) </strong>: Congrats to Ying on being selected as an Amazon Fellow! </h4></li>
        <li><h4> <strong> (10/06/23) </strong>: We are grateful to receive a grant from the Amazonâ€“VT Initiative to support our research on conversational AI (<a class="a:link" href="https://news.vt.edu/articles/2023/09/amazon-virginia-tech-initiative-announces-support-for-two-amazon.html"  target=_blank>VT News Article</a>). </h4></li>
        <li><h4> <strong> (9/12/23) </strong>: <img width=18px height=18px src="style/champion.png" />HokieBot team won the <strong>Third Place on Scientific Competition (awarded $25,000)</strong> for the Amazon Alexa Prize SocialBot Grand Challenge 5! Check out our <a class="a:link" href="https://assets.amazon.science/7c/3e/2f10d3b04c79bb67b762b3c9b55f/hokiebottowards-personalized-open-domain-chatbot-with-long-term-dialogue-management-and-customizable-automatic-evaluation.pdf"  target=_blank>report</a> and <a class="a:link" href="https://www.amazon.science/alexa-prize/socialbot-grand-challenge/2022"  target=_blank>news announcement</a> from Amazon Science.</h4></li>
        <li><h4> <strong> (8/20/23) </strong>: Serving as an Area Chair of EACL'2023 and SPC of AAAI'2023.</h4>
        <li><h4> <strong> (7/28/23) </strong>: <img width=18px height=18px src="style/champion.png" />Super excited and honored to receive the <strong>Best Paper Award Honorable Mention</strong> from SIGIR'2023! Welcome to check out our <a class="a:link" href="https://dl.acm.org/doi/pdf/10.1145/3539618.3591879"  target=_blank>Multimodal Fact Checking and Explanaton Generation</a> paper and <a class="a:link" href="https://github.com/VT-NLP/Mocheg"  target=_blank>Github repo</a>!</h4></li>
        <li><h4> <strong> (7/12/23) </strong>: Serving as a publication committee co-chair of NAACL'2024!</h4></li>
        <li><h4> <strong> (7/10/23) </strong>: <img width=18px height=18px src="style/champion.png" />Super honored to share that our <a class="a:link" href="https://aclanthology.org/2023.acl-long.641.pdf"  target=_blank>MultiInstruct</a> work received the <strong>Outstanding Paper Award</strong> from ACL'2023! Welcome to check out our <a class="a:link" href="https://github.com/VT-NLP/MultiInstruct"  target=_blank>project page.</a></h4></li>
        <li><h4> <strong> (7/6/23) </strong>: We are very grateful to receive a new grant from DARPA for the <a class="a:link" href="https://www.darpa.mil/program/environment-driven-conceptual-learning"  target=_blank>ECOLE</a> program!</h4></li>
        <!-- <li><h4> <strong> (5/10/23) </strong>: I'm very honored to receive the Department Rising Star Faculty Award! </h4></li> -->
        <li><h4> <strong> (5/1/23) </strong>: We have 5 papers accepted by ACL'23! Congrats to Zhiyang, Ying, Minqian, Sijia and all collaborators! </h4></li>
<!--         <li> <h4> <strong> (3/31/23)</strong>: Our work on Multimodal Fact Checking is accepted by SIGIR'23 Resource Track. Congrats to Barry!</h4></li> -->
        <li> <h4> <strong> (3/28/23)</strong>: Very grateful to receive the <a class="a:link" href="https://news.vt.edu/articles/2023/04/lifu-huang-receives-nsf-career-award-to-lay-new-ground-for-infor.html"  target=_blank>NSF CAREER Award</a>!</h4></li>
        <li> <h4> <strong> (3/10/23)</strong>: Congrats to Zhiyang, Minqian and Ying on receiving internship offers from Amazon Alexa AI, AWS Research Lab (NYC) and Apple Research.</h4></li>
        <!-- <li> <h4> <strong> (12/20/22)</strong>: Check out our recent <a class="a:link" href="https://arxiv.org/pdf/2212.10773.pdf"  target=_blank>arXiv</a> that introduces the first multimodal instruction tuning benchmark resource and model.</h4></li> -->
        <li> <h4> <strong> (12/18/22)</strong>: Serving as a publication committee co-chair of ACL'2023, SAC of ACL'2023, AC of EMNLP'2023, and SPC of IJCAI'2023.</h4></li>
        <li> <h4> <strong> (10/28/22)</strong>: We are grateful to receive a gift fund from Google and Intuit.</h4></li>
        <li> <h4> <strong> (10/26/22)</strong>: Our team - HokieBot is selected as one of the 9 university teams for the Alexa Prize SocialBot Grand Challenge 5. We are grateful for all the support from Amazon Alexa.</h4></li>
        <!-- <li> <h4> <strong> (10/9/22)</strong>: Serving as a publication committee co-chair of ACL'2023.</h4></li> -->
        <!-- <li> <h4> <strong> (10/6/22)</strong>: Two papers on long text generation and federated learning on knowledge graphs accepted by EMNLP'2022.</h4></li> -->
        <li> <h4> <strong> (9/30/22)</strong>: Talk at USC AI Seminar: "Towards Open World Event Extraction with Weak Supervision".</h4></li>
        <li> <h4> <strong> (8/15/22)</strong>: Our work on <a class="a:link" href="https://arxiv.org/pdf/2204.07275.pdf"  target=_blank>Incremental Prompting for Continual Event Detection</a> is accepted by COLING'22. Congrats to Minqian!</h4></li>
        <li> <h4> <strong> (8/1/22)</strong>: Serving as Area Chair (AC) for COLING'2022.</h4></li>
        <li> <h4> <strong> (6/22/22)</strong>: Initiated workshop "Indirect, Weak and Self Supervision for Knowledge Extraction" accepted by AKBC2022. <a class="a:link" href="https://iwskr.github.io/"  target=_blank>Call For Papers!</a></h4></li>
        <li> <h4> <strong>  (6/21/22)</strong>: We are very grateful to receive a new grant from Meta AI to support our research on multimodal entity linking.</h4></li>
        <!-- <li> <h4> <strong>  (4/7/22)</strong>: Our work on <a class="a:link" href="http://arxiv.org/abs/2104.09570"  target=_blank>Temporal Event Relation Extraction</a> is accepted by NAACL'2022. Congrats to Shuaicheng!</h4></li> -->
        <li> <h4> <strong>  (3/31/22)</strong>: Recent talks at UNC Greensboro, STR, and Data Intelligence Workshop on Transferable and Scalable Event Extraction</h4></li>
        <!-- <li> <h4> <strong>  (3/30/22)</strong>: Our work on <a href="https://arxiv.org/pdf/2201.07099.pdf" target=_blank>Commonsense Prompting for Future Event Generation</a> is accepted by SIGIR'2022. </h4></li> -->
<!--         <li> <h4> <strong>  (3/22/22)</strong>: Welcome <a href="https://yingshen-ys.github.io/" target=_blank> Ying Shen </a> to join our lab!</h4></li> -->
        <li> <h4> <strong>  (3/8/22) </strong>: Our SimBot team (to advance Embodied AI) is featured on the <a href="https://vtx.vt.edu/articles/2022/03/virginia-tech-team-selected-as-finalist-in-alexa-prize.html" target=_blank> VT News </a> today!</h4></li>        
        <!-- <li> <h4> <strong>  (2/24/22)</strong>: Two papers are accepted by ACL'2022. Congrats to Sijia and Zhe.</h4></li> -->
<!--         <li> <h4> <strong>  (2/22/22)</strong>: Talk at STR about our new <a href="https://arxiv.org/abs/2110.07476" target=_blank> Query-and-Extract Event Extraction </a> paradigm (new state of the art for event extraction!!).</h4></li>
 -->        
 		<!-- <li> <h4> <strong>  (12/28/21)</strong>: Congrats to Sijia and Zhiyang on receiving internship offers from Amazon AWS Research Lab (NYC) and Alexa AI.</h4></li>   -->
        <li> <h4> <strong>  (12/15/21)</strong>: Will give a tutorial on <a href="https://aclanthology.org/2022.naacl-tutorials.3/" target=_blank> New Frontiers of Information Extraction </a> at NAACL'2022.</h4></li>
        <li> <h4> <strong>  (12/10/21)</strong>: Very excited to receive a new grant for the DARPA <a href="https://www.darpa.mil/program/knowledge-management-at-scale-and-speed" target=_blank>KMass</a> program.</h4></li>
<!--         <li> <h4> <strong>  (12/1/21)</strong>: One paper on multi-modal question answering accepted by AAAI'2022.</h4></li>
 -->        <!-- <li> <h4> <strong>  (11/15/21)</strong>: Receiving a new grant on <a href="https://www.amazon.science/alexa-prize/simbot-challenge" target=_blank>SimBot Challenge</a> from Amazon Alexa. Thanks Amazon!.</h4></li> -->
<!--         <li> <h4> <strong>  (10/15/21)</strong>: Check our recent arXiv paper on a new state-of-the-art event extraction approach.</h4></li>
 -->        
 		<!-- <li> <h4> <strong>  (10/15/21)</strong>: One paper accepted by EMNLP'2021 main conference and one by the EANCS workshop of EMNLP'2021.</h4></li> -->
        <!-- <li> <h4> <strong>  (05/30/21)</strong>: Giving talks about Transferable and Scalable Event Extraction at Baidu and Data Intelligence Workshop</h4></li> -->
        <!-- <li> <h4> <strong>  (05/05/21)</strong>: One paper accepted by ACL'2021</h4></li> -->
        <!-- <li> <h4> <strong>  (03/30/21)</strong>: Will serve as an Area Chair of NLPCC'2021</h4></li> -->
        <!-- <li> <h4> <strong>  (03/24/21)</strong>: Receiving the 2021 Amazon Research Awards. Thanks Amazon!</h4></li> -->
        <!-- <li> <h4> <strong>  (03/01/21)</strong>: Will serve as an Area Chair for Application track of EMNLP'2021</h4></li> -->
        <!-- <li> <h4> <strong>  (11/28/20)</strong>: Very excited to start my new career at Virginia Tech</h4></li> -->
<!--         <li> <h4> <strong>  (10/27/20)</strong>: Will serve as an Area Chair for IE track of NAACL'2020</h4></li>
        <li> <h4> <strong>  (10/17/20)</strong>: Will serve as a Senior Program Committee Member for IJCAI'2020</h4></li>
        <li> <h4> <strong>  (10/01/20)</strong>: Our work on <a href="https://blender.cs.illinois.edu/paper/reviewrobot2020.pdf" target=_blank>ReviewRobot</a> is accepted by INLG'2020!</h4></li>
        <li> <h4> <strong>  (10/01/20)</strong>: Our work on <a href="https://blender.cs.illinois.edu/paper/eventschemadetection2020.pdf" target=_blank>semi-supervised new event type induction and event detection</a> is accepted by EMNLP'2020! Code will be released here.</h4></li> -->
        <li>...</li>
        </ul>
        </div>

      </div>
      <br />
    </div>
  </div>
</body>
</html>
